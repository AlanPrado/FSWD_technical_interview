# Question 1

For a word n be an anagram of m word, all the letters in n should be contained
in m.

For example,
    m: "aaab"
    n: "aab"

Note that the amount of letters "a" from n should have less or equal the amount
of letter "a" from m.

To solve this problem we can count the frequency of each letter from the words
and verify if satisfy the both criteria explained above.


* Step 1: Counting letter frequency

For improve the letter search performance, we can make use of a dictionary.

m: { a: 3, b: 1 } and n: { a: 2, b: 1 }

* Step 2: Comparison

n['a'] <= m['a'] and n['b'] <= m['b']

Thus, n is an anagram of m.

## Complexity

Consider that n is length m.

Worst case: when len(n) = len(m)
Average case: len(n) / 2 = len(m)
Best case: len(n) = len(m) = 1

## Time Complexity

____________| Worst _________| Average ________| Best _________
Step 1      | n + n          | n + n / 2       | 1 + 1
Step 2      | 1              | 13              | 26
O           | O(n)           | O(n)            | O(1)

* Step 2: Comparison - Assuming that we have 26 letters at most, but the
important aspect is that we have a constant amount letter depending on charset.

## Space Complexity

____________| Worst _________| Average ________| Best _________
Step 1      | 2 * (26 + 26)  | 2 * (13 + 13)   | 2 * (1 + 1)
O           | O(1)           | O(1)            | O(1)

# Question 2

To find the longest palindromic inside a word, it's necessary to check if subset
of the word is a palindrome.

Given the word "house", check if it a palindrome

Evidently, it's possible to verify that "house" is not a palindrome for the
simple fact that "h" is different than "e". The longest palindrome in the word
"house" has only a single letter. The first part half of the palindrome is like
a mirror of the second half of the palindrome.

These observations are simple but helps to reduce the amount of checkings in a
significant way once that we only need to verify palindromes between pairs of
equal letters. If we don't have any equal letters, the longest palindrome should
have only one letter. Also, if the word is reversed, the string hash function
can helps with comparison between the first half and the second half of the
palindrome.

Algorithm:

1 - Reverse the word
2 - Store the index of each letter
3 - For each letter:
    2.1 - Verify if the number of indices is equal to 1, create a subset of
          the letter l
    2.2 - Otherwise, creates a subset through combination of two indices
4 - Sort the subsets in descending by *priority
5 - For each subset:
    4.1 - If the subset is a palindrome, return the word

*priority = higher index - lower index

Example:

Given the word "banana",

1 - Reverse the word
    "ananab"

2 - Index the word:
    {
        "b": [0],
        "a": [1, 3, 5],
        "n": [2, 4]
    }

3 - Create subsets
    subsets = [(0, 0), (1, 5), (1, 3), (3, 5), (1, 1), (2, 4), (2, 2)]

4 - Sort subsets
    subsets = [(1, 5), (1, 3), (2, 4), (3, 5), (0, 0), (1, 1), (2, 2)]

5 - Check isPalindrome(word[1, 5]), then return "anana"

Improvements made in the algorithm:
    * Defer the subset calculation to be lazy calculated at step 4 in order to
    save memory and processing;
    * Skip the sort step using a priority queue to store the subsets and sort
    them in insertion time.

## Complexity

Consider that n is number of letters of the word "a".

Worst case: lots of repeated letters, but none palindromes like "abcabcabcabcabcabc"
Average case: some repeated letters, like "some repeated letters"
Best case: one single letter, "a"

## Time Complexity

____________| Worst ______________________________| Average ________| Best _________
Step 2      | n                                   | n               | 1

____________| Worst ____________________________________| Average _______________________________| Best _________
Step 1      | n                                         | n                                      | 1
Step 3      | n + 3 * ((n / 3) * ((n / 3) - 1) / 2 + 1) | n + sum(for each k in ul, C(k, 2) + 1) | 1 + 1
Step 4      | n                                         | k                                      | 1
Step 5      | 3 * (Step 2)                              | 3 * (Step 2)                           | 3 * (Step 2)
O           | O(n^2)                                    | O(n)                                   | O(1)

ul: unique letters
C(k, 2) = k! / (2! * (k − 2)!), where k is number of indices of a single letter = constant

## Space Complexity

________________________________| Worst ___________________| Average ________________________________| Best _________
Subsets.charMap                 | 3 * (n / 3 + 1)          | sum(for each ul, len(k))                | 2 * (1 + 1)
Subsets.subsetsSize             | 3 * 2                    | count(ul) * 2                           | 2 * 1
Subsets.numSubsetsPerLetterPair | 3 * 2                    | count(ul) * 2                           | 2 * 1
Subsets.self.subsets            | C(n / 3, 2) * 3 * Subset | sum(for each k in ul, C(k, 2)) * Subset | 2 * Subset
O                               | O(n)                     | O(n)                                    | O(1)

3 * C(n / 3, 2) = 3 * (n / 3)! / (2! * (n / 3 - 2)!) = constant
sum(for each k in ul, C(k, 2)) = constant
Subset = constant

# Question 3

To find the minimum spanning tree there are four classic algorithms:
    1 - Borůvka's algorithm
    2 - Prim's algorithm
    3 - Kruskal's algorithm
    4 - Reverse-delete algorithm

I'll provide an example an short overview on how the algorithm works.

Given the graph:
   _____       _____
+--|_A_|---1---|_B_|---+
|       \              |
5        +-7-+         8
|  _____      \_____   |
+--|_C_|---4---|_D_|---+

1 - Borůvka's algorithm
    For each node of the graph, traverse its edge with lower weight.
    This procedure can create several forests. Keep doing this until you have
    just one tree.
    If the both nodes of an edge belongs to the same forest, you can't traverse
    them to avoid cycles.
    Note that the discovering order depends on the nodes order in the graph.
    Step 1 - A visit edge 1 - AB
    Step 2 - B visit edge 1 - AB
    Step 3 - C visit edge 4 - AB, CD
    Step 4 - D visit edge 4 - AB, CD
    Step 5 - AB visit edge 5 - ABCD

2 - Prim's algorithm
    Choose a random node as root node. From the root node, visit the next node
    with lower edge weight. Keep doing this until you visit all the nodes.
    If the node you are trying to visit was already visited, you can't traverse
    it to avoid cycles.
    Note that the discovering order depends on the previous node visited.
    Step 1 - Root is C - C
    Step 2 - From C visit D - CD
    Step 3 - From CD visit A - CDA
    Step 3 - From CDA visit B - CDAB

3 - Kruskal's algorithm
    Sort the edges by weight in ascending order. For each edge, visit the nodes
    that were not visited. This procedure can create several forests. Keep
    doing this until you have just one tree.
    If the both nodes of an edge belongs to the same forest, you can't traverse
    them to avoid cycles.
    Note that the discovering order depends on the edges with lower weights.
    Step 1 - Visit edge 1 - AB
    Step 2 - Visit edge 4 - AB, CD
    Step 3 - Visit edge 5 - ABCD

4 - Reverse-delete algorithm
    Sort the edges by weight in descending order. For each edge, verify if it's
    a cycle, and erase it in positive case. After you visit all the edges, you
    will have a MST.
    Note that the discovering order depends on the edges with higher weights.
    Step 1 - Verify if edge 8 is cycle - erase
    Step 2 - Verify if edge 7 is cycle - erase
    Step 3 - Verify if edge 5 is cycle - do nothing
    Step 4 - Verify if edge 4 is cycle - do nothing
    Step 5 - Verify if edge 1 is cycle - do nothing

The graph is structured as an adjacency list and I would like to avoid handling
the following issues:
    * Indexing edges by weight in ascending order;
    * Create a disjoint-set data structure to deal with several forests or some
    variation of that.

I could create a priority queue to index the edges by weight, but with an
adjacency list, using the Prim's algorithm, I can visit the edges only when I
need instead of visiting all the edges at the beginning. This could save some
memory, especially if we are dealing with a huge complete graph.
Also, it's not necessary to work with several trees using the Prim's algorithm.

Thus, the Prim's algorithm was selected to be implemented.

## Complexity

Consider that n is number of vertex times number of edges(e).

Worst case: v * e = n, e^2 = v (complete graph)
Average case: v * e = n, where e^2 < v
Best case: v = 2, e = 1

## Time Complexity

________________| Worst________________| Average __________________| Best _________
initialize      | 6v + 1               | 6v + 1                    | 2 + 1
findMinWeight   | 10v                  | 10v                       | 10 * 2
visitNextVertex | v * e                | v * e                     | 2
addAdjList      | 2v                   | 2v                        | 2 * 2
O               | O(n)                 | O(n)                      | O(1)

## Space Complexity

___________________| Worst_____| Average ______| Best _________
parents            | 2v        | 2v            | 2 * 2
weightPerVertex    | 2e        | 2e            | 2 * 1
verticesPerWeight  | 2v        | 2v            | 2 * 2
weights            | 2v        | 2v            | 2 * 1
F                  | v         | v             | 2
Q                  | 2*2v      | 2*2v          | 2 * 2
O                  | O(n)      | O(n)          | O(1)

## External resources:
- [Minimum spanning tree](https://en.wikipedia.org/wiki/Minimum_spanning_tree);
- [Borůvka's algorithm](https://en.wikipedia.org/wiki/Bor%C5%AFvka%27s_algorithm);
- [Prim's algorithm](https://en.wikipedia.org/wiki/Prim%27s_algorithm);
- [Kruskal's algorithm](https://en.wikipedia.org/wiki/Kruskal%27s_algorithm);
- [Reverse-delete algorithm](https://en.wikipedia.org/wiki/Reverse-delete_algorithm);
- [Prim's algorithm video](https://www.youtube.com/watch?v=z1L3rMzG1_A).

# Question 4

To find the least common ancestor between two nodes, just navigate in each node
until you found the root. For each path verify the first common node between
the nodes.

* Step 1: Find the parent

To find the parent, we navigate through all available nodes until we find the
node's parent.

For example,

When T = [[1, 0, 1],
          [0, 0, 0],
          [0, 0, 0]]

and  n1 = 0

We have to verify if each index in column 0 has the value 1.
If it has, the row (node) should be returned, otherwise check the next row
until all rows be checked.

This is a very costly operation because you must go through all rows and
columns in the worst case. To improve the performance, we could change T matrix
for a tree or a linked list.

* Step 2: Find the ancestors

For a given node find its parent until the parent be the root node.

To improve the performance of this step we allow the user to choose if the list
returned should be indexed or not and allow the user to create a stop condition.

If the path is indexed, does not maintain the order and is helpful for lookup,
otherwise it will maintain the finding order.

The stop condition can be used to avoid traversing until the root if a farthest
node is found first.

* Step 3: Find the farthest node

Find the ancestors of the node n1 without order. Then, perform the ancestor
search of the node n2 with order and a stop condition. Finally, pop the last
ancestor of n2.

## Complexity

Consider that n is number of nodes in the matrix.

Worst case: n = n
Average case: n = floor(n / 2)
Best case: n = 3

## Time Complexity

______________| Worst _______________ | Average ___________________________________ | Best _________
Step 1, Step2 | (n * (n + 1)) / 2 + 1 | (floor(n / 2) * (floor(n / 2) + 1)) / 2 + 1 | 2
Step 3        | n + 2                 | floor(n / 2) * 2 + 1                        | 3
O             | O(n^2)                | O(n^2)                                      | O(1)

## Space Complexity

________________| Worst ___________ | Average _____________ | Best _________
availableNodes  | n                 | n                     | 3
ancestorN1      | n - 1             | floor(n / 2)          | 1
ancestorN2      | 1                 | floor(n / 2)          | 1
O               | O(n)              | O(n)                  | O(1)

# Question 5

To find mth element from the end of the linked list, we need to navigate
through all the nodes twice. The first time we count the number of nodes
and the second time we return the mth element of the list.

* Step 1: Length

To accomplish this task we just need traverse all the nodes.

* Step 2: Length

We just need traverse the nodes until length - mth == 0.

## Complexity

Consider that n is number of nodes.

Worst case: m = 1
Average case: m = n / 2
Best case: m = n and n = 1

## Time Complexity

_______| Worst ________ | Average _________ | Best ____________
Step 1 | n * 2          | n + n / 2         | 1 + 1
O      | O(n)           | O(n)              | O(1)

## Space Complexity

_______| Worst ____________ | Average ____________ | Best ____________
Step 1 | 3                  | 3                    | 3
O      | O(1)               | O(1)                 | O(1)
